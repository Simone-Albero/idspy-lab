# @package _global_
pretraining: {}

defaults:
  - /model@pretraining.model: contrastive_tabular_autoencoder
  - /loss@pretraining.loss: nt_xent
  - /model@fine_tuning.model: tabular_classifier
  - /loss@fine_tuning.loss: classification
  - override /loops: default
  - override /optimizer: adamw
  - override /scheduler: one_cycle
  - _self_

type: unsupervised_contrastive_classifier

experiment:
  # exclude_background: true
  name: base
  exclude_background: false
  n_samples: 500

fine_tuning:
  model:
    args:
      # num_classes: 10
      num_classes: 11
  frozen_depth: 0
